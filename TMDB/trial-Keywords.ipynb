{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle - TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Left to consider:\n",
    "\n",
    "cast - different approach\n",
    "crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rev = {'en': 16.201695631547217,\n",
    " 'fr': 13.718204235553607,\n",
    " 'ru': 13.815132182879807,\n",
    " 'es': 14.645970166012837,\n",
    " 'hi': 15.371121660763546,\n",
    " 'ja': 15.818050019285394,\n",
    " 'it': 14.610307296701814,\n",
    " 'ko': 14.561503498231747,\n",
    " 'cn': 15.720496475312752,\n",
    " 'zh': 15.246036823468886,\n",
    " 'de': 14.583008872938295,\n",
    " 'ta': 15.073328869838628,\n",
    " 'sv': 13.405171677584297}\n",
    "\n",
    "train['l_rev'] = train['original_language'].map(l_rev).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['coll_id'] = train['belongs_to_collection'].fillna('[{\"id\":0}]').map(\n",
    "    lambda x: (ast.literal_eval(x))[0]['id'])\n",
    "colls = pd.read_csv('collections.csv',index_col=0)\n",
    "train['coll_rev_logav'] = train['coll_id'].map(colls['log_of_averages']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = pd.read_csv('genres.csv',index_col=0)\n",
    "train['genres_id'] = train['genres'].fillna('[{\"id\":-1}]').map(\n",
    "    lambda x: [i['id'] for i in (ast.literal_eval(x))])\n",
    "gen_rev = dict(genres['log_revenue'])\n",
    "gen_rev[-1] = 0\n",
    "train['genre_ave'] = train['genres_id'].map(lambda x: np.array([gen_rev[g] for g in x]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### production company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['production_ids'] = train['production_companies'].fillna('[{\"id\":-123}]').map(\n",
    "    lambda x: [i['id'] for i in (ast.literal_eval(x))])\n",
    "productions = pd.read_csv('production_companies_short.csv',index_col=0)\n",
    "prod_rev = dict(productions['revenue'])\n",
    "train['production_revs'] = train['production_ids'].map(lambda x: ([prod_rev[p] for p in x if p in prod_rev]))\n",
    "train['prod_ave'] = train['production_revs'].map(lambda x: np.array(x).mean() if len(x)>0 else 0)\n",
    "train['prod_top'] = train['production_revs'].map(lambda x: np.array(x).max() if len(x)>0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year'] = train['release_date'].map(lambda x: (x.split('/'))[2])\n",
    "train['year'] = train['year'].astype(int)\n",
    "train['year'] = train['year'].map(lambda x: x+1900 if x>17 else x+2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['runtime'] = train['runtime'].fillna(107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spoken language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['spoken'] = train['spoken_languages'].fillna('[{\"iso_639_1\":\"nan\"}]').map(\n",
    "    lambda x: [a['iso_639_1'] for a in ast.literal_eval(x)])\n",
    "\n",
    "train['spoken'].map(lambda x: 'en' in x).sum()\n",
    "\n",
    "\n",
    "limit=40\n",
    "\n",
    "uniques = []\n",
    "for i in train['spoken']:\n",
    "    uniques.extend(i)\n",
    "uniques = set(uniques)\n",
    "\n",
    "counts = {}\n",
    "for u in uniques:\n",
    "    c = train['spoken'].map(lambda x: u in x).sum()\n",
    "    counts[u] = c\n",
    "    \n",
    "spoken = pd.DataFrame.from_dict(counts,orient='index',columns=['count'])\n",
    "\n",
    "spoken_names = []\n",
    "for u in counts:\n",
    "    if (counts[u]> limit):\n",
    "        name = f'spoken_{u}'\n",
    "        spoken_names.append(name)\n",
    "        train[name] = train['spoken'].map(lambda x: u in x).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['kwrds'] = train['Keywords'].fillna(\"[{'id':-222}]\").map(\n",
    "    lambda x: [i['id'] for i in (ast.literal_eval(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_k = []\n",
    "for i in train['kwrds']:\n",
    "    all_k.extend(i)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "k_counts = Counter(all_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7401\n",
      "5 771\n",
      "10 309\n",
      "15 176\n",
      "20 112\n",
      "25 80\n",
      "30 53\n",
      "35 38\n",
      "40 31\n",
      "45 27\n",
      "50 22\n",
      "55 20\n",
      "60 19\n",
      "65 16\n",
      "70 14\n",
      "75 9\n",
      "80 8\n",
      "85 7\n",
      "90 6\n",
      "95 6\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100,5):\n",
    "    l = len([k for k in k_counts if k_counts[k]>i])\n",
    "    print(i,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_to_use = [k for k in k_counts if k_counts[k]>25]\n",
    "\n",
    "k_names = []\n",
    "for k in ks_to_use:\n",
    "    name = f'kwrd_{k}'\n",
    "    k_names.append(name)\n",
    "    train[name] = train['kwrds'].map(lambda x: k in x).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['revenue'].map(math.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.013398121034763"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score so far (reference)\n",
    "columns = ['popularity','budget',\n",
    "           'l_rev',\n",
    "           'coll_rev_logav',\n",
    "           'genre_ave',\n",
    "          'prod_top','prod_ave',\n",
    "           'year', 'runtime',\n",
    "          *spoken_names]\n",
    "\n",
    "X = train[columns]\n",
    "-cross_val_score(boost,X,y,cv=10,scoring='neg_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.030610740266548"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score so far (reference)\n",
    "columns = ['popularity','budget',\n",
    "           'l_rev',\n",
    "           'coll_rev_logav',\n",
    "           'genre_ave',\n",
    "          'prod_top','prod_ave',\n",
    "           'year', 'runtime',\n",
    "          *spoken_names,\n",
    "          *k_names]\n",
    "\n",
    "X = train[columns]\n",
    "-cross_val_score(boost,X,y,cv=10,scoring='neg_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['l_rev'] = test['original_language'].map(l_rev).fillna(13.61844005781211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['coll_id'] = test['belongs_to_collection'].fillna('[{\"id\":0}]').map(lambda x: (ast.literal_eval(x))[0]['id'])\n",
    "test['coll_rev_logav'] = test['coll_id'].map(colls['log_of_averages']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['genres_id'] = test['genres'].fillna('[{\"id\":-1}]').map(lambda x: [i['id'] for i in (ast.literal_eval(x))])\n",
    "test['genre_ave'] = test['genres_id'].map(lambda x: np.array([gen_rev[g] for g in x]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['production_ids'] = test['production_companies'].fillna('[{\"id\":-123}]').map(\n",
    "    lambda x: [i['id'] for i in (ast.literal_eval(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['production_revs'] = test['production_ids'].map(lambda x: ([prod_rev[p] for p in x if p in prod_rev]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prod_ave'] = test['production_revs'].map(lambda x: np.array(x).mean() if len(x)>0 else 0)\n",
    "test['prod_top'] = test['production_revs'].map(lambda x: np.array(x).max() if len(x)>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value - I filled with wikipedia info\n",
    "test.loc[828,'release_date'] = '05/01/00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['year'] = test['release_date'].map(lambda x: (x.split('/'))[2])\n",
    "test['year'] = test['year'].astype(int)\n",
    "test['year'] = test['year'].map(lambda x: x+1900 if x>17 else x+2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['runtime'] = test['runtime'].fillna(107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['spoken'] = test['spoken_languages'].fillna('[{\"iso_639_1\":\"nan\"}]').map(lambda x: [a['iso_639_1'] for a in ast.literal_eval(x)])\n",
    "for u in counts:\n",
    "    if (counts[u]> limit):\n",
    "        name = f'spoken_{u}'\n",
    "        spoken_names.append(name)\n",
    "        test[name] = test['spoken'].map(lambda x: u in x).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['kwrds'] = test['Keywords'].fillna(\"[{'id':-222}]\").map(\n",
    "    lambda x: [i['id'] for i in (ast.literal_eval(x))])\n",
    "\n",
    "for k in ks_to_use:\n",
    "    name = f'kwrd_{k}'\n",
    "    test[name] = test['kwrds'].map(lambda x: k in x).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      revenue\n",
       "id           \n",
       "3001  1000000\n",
       "3002  1000000\n",
       "3003  1000000\n",
       "3004  1000000\n",
       "3005  1000000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('sample_submission.csv',index_col='id')\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['popularity','budget',\n",
    "           'l_rev',\n",
    "           'coll_rev_logav',\n",
    "           'genre_ave',\n",
    "          'prod_top','prod_ave',\n",
    "           'year', 'runtime',\n",
    "          *spoken_names,\n",
    "          *k_names]\n",
    "\n",
    "X = train[columns]\n",
    "\n",
    "X_test = test[columns]\n",
    "\n",
    "boost.fit(X,y)\n",
    "pred = boost.predict(X_test)\n",
    "pred = np.exp(pred)\n",
    "submit['revenue'] = pred\n",
    "submit.to_csv('0903-k_80.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
