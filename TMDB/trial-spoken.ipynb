{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle - TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Left to consider:\n",
    "\n",
    "Keywords\n",
    "cast - different approach\n",
    "crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rev = {'en': 16.201695631547217,\n",
    " 'fr': 13.718204235553607,\n",
    " 'ru': 13.815132182879807,\n",
    " 'es': 14.645970166012837,\n",
    " 'hi': 15.371121660763546,\n",
    " 'ja': 15.818050019285394,\n",
    " 'it': 14.610307296701814,\n",
    " 'ko': 14.561503498231747,\n",
    " 'cn': 15.720496475312752,\n",
    " 'zh': 15.246036823468886,\n",
    " 'de': 14.583008872938295,\n",
    " 'ta': 15.073328869838628,\n",
    " 'sv': 13.405171677584297}\n",
    "\n",
    "train['l_rev'] = train['original_language'].map(l_rev).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['coll_id'] = train['belongs_to_collection'].fillna('[{\"id\":0}]').map(\n",
    "    lambda x: (ast.literal_eval(x))[0]['id'])\n",
    "colls = pd.read_csv('collections.csv',index_col=0)\n",
    "train['coll_rev_logav'] = train['coll_id'].map(colls['log_of_averages']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = pd.read_csv('genres.csv',index_col=0)\n",
    "train['genres_id'] = train['genres'].fillna('[{\"id\":-1}]').map(\n",
    "    lambda x: [i['id'] for i in (ast.literal_eval(x))])\n",
    "gen_rev = dict(genres['log_revenue'])\n",
    "gen_rev[-1] = 0\n",
    "train['genre_ave'] = train['genres_id'].map(lambda x: np.array([gen_rev[g] for g in x]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### production company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['production_ids'] = train['production_companies'].fillna('[{\"id\":-123}]').map(\n",
    "    lambda x: [i['id'] for i in (ast.literal_eval(x))])\n",
    "productions = pd.read_csv('production_companies_short.csv',index_col=0)\n",
    "prod_rev = dict(productions['revenue'])\n",
    "train['production_revs'] = train['production_ids'].map(lambda x: ([prod_rev[p] for p in x if p in prod_rev]))\n",
    "train['prod_ave'] = train['production_revs'].map(lambda x: np.array(x).mean() if len(x)>0 else 0)\n",
    "train['prod_top'] = train['production_revs'].map(lambda x: np.array(x).max() if len(x)>0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year'] = train['release_date'].map(lambda x: (x.split('/'))[2])\n",
    "train['year'] = train['year'].astype(int)\n",
    "train['year'] = train['year'].map(lambda x: x+1900 if x>17 else x+2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['runtime'] = train['runtime'].fillna(107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spoken language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['spoken'] = train['spoken_languages'].fillna('[{\"iso_639_1\":\"nan\"}]').map(lambda x: [a['iso_639_1'] for a in ast.literal_eval(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2618"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['spoken'].map(lambda x: 'en' in x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=5\n",
    "\n",
    "uniques = []\n",
    "for i in train['spoken']:\n",
    "    uniques.extend(i)\n",
    "uniques = set(uniques)\n",
    "\n",
    "counts = {}\n",
    "for u in uniques:\n",
    "    c = train['spoken'].map(lambda x: u in x).sum()\n",
    "    counts[u] = c\n",
    "    \n",
    "spoken = pd.DataFrame.from_dict(counts,orient='index',columns=['count'])\n",
    "\n",
    "spoken_names = []\n",
    "for u in counts:\n",
    "    if (counts[u]> limit):\n",
    "        name = f'spoken_{u}'\n",
    "        spoken_names.append(name)\n",
    "        train[name] = train['spoken'].map(lambda x: u in x).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_ar</th>\n",
       "      <th>spoken_de</th>\n",
       "      <th>spoken_en</th>\n",
       "      <th>spoken_cn</th>\n",
       "      <th>spoken_fr</th>\n",
       "      <th>spoken_zh</th>\n",
       "      <th>spoken_es</th>\n",
       "      <th>spoken_hi</th>\n",
       "      <th>spoken_ja</th>\n",
       "      <th>spoken_ta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt2637294</td>\n",
       "      <td>en</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0368933</td>\n",
       "      <td>en</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://sonyclassics.com/whiplash/</td>\n",
       "      <td>tt2582802</td>\n",
       "      <td>en</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              belongs_to_collection    budget  \\\n",
       "0   1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
       "1   2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
       "2   3                                                NaN   3300000   \n",
       "\n",
       "                                              genres  \\\n",
       "0                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "1  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "2                      [{'id': 18, 'name': 'Drama'}]   \n",
       "\n",
       "                            homepage    imdb_id original_language  \\\n",
       "0                                NaN  tt2637294                en   \n",
       "1                                NaN  tt0368933                en   \n",
       "2  http://sonyclassics.com/whiplash/  tt2582802                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                    Hot Tub Time Machine 2   \n",
       "1  The Princess Diaries 2: Royal Engagement   \n",
       "2                                  Whiplash   \n",
       "\n",
       "                                            overview  popularity    ...     \\\n",
       "0  When Lou, who has become the \"father of the In...    6.575393    ...      \n",
       "1  Mia Thermopolis is now a college graduate and ...    8.248895    ...      \n",
       "2  Under the direction of a ruthless instructor, ...   64.299990    ...      \n",
       "\n",
       "  spoken_ar spoken_de spoken_en spoken_cn  spoken_fr spoken_zh spoken_es  \\\n",
       "0         0         0         1         0          0         0         0   \n",
       "1         0         0         1         0          0         0         0   \n",
       "2         0         0         1         0          0         0         0   \n",
       "\n",
       "  spoken_hi spoken_ja spoken_ta  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['revenue'].map(math.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.986956713697304"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score so far (reference)\n",
    "columns = ['popularity','budget',\n",
    "           'l_rev',\n",
    "           'coll_rev_logav',\n",
    "           'genre_ave',\n",
    "          'prod_top','prod_ave',\n",
    "           'year', 'runtime']\n",
    "\n",
    "X = train[columns]\n",
    "-cross_val_score(boost,X,y,cv=10,scoring='neg_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.973993086328734"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['popularity','budget',\n",
    "           'l_rev',\n",
    "           'coll_rev_logav',\n",
    "           'genre_ave',\n",
    "          'prod_top','prod_ave',\n",
    "           'year', 'runtime',\n",
    "          *spoken_names]\n",
    "\n",
    "X = train[columns]\n",
    "-cross_val_score(boost,X,y,cv=10,scoring='neg_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['l_rev'] = test['original_language'].map(l_rev).fillna(13.61844005781211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['coll_id'] = test['belongs_to_collection'].fillna('[{\"id\":0}]').map(lambda x: (ast.literal_eval(x))[0]['id'])\n",
    "test['coll_rev_logav'] = test['coll_id'].map(colls['log_of_averages']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['genres_id'] = test['genres'].fillna('[{\"id\":-1}]').map(lambda x: [i['id'] for i in (ast.literal_eval(x))])\n",
    "test['genre_ave'] = test['genres_id'].map(lambda x: np.array([gen_rev[g] for g in x]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['production_ids'] = test['production_companies'].fillna('[{\"id\":-123}]').map(\n",
    "    lambda x: [i['id'] for i in (ast.literal_eval(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['production_revs'] = test['production_ids'].map(lambda x: ([prod_rev[p] for p in x if p in prod_rev]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prod_ave'] = test['production_revs'].map(lambda x: np.array(x).mean() if len(x)>0 else 0)\n",
    "test['prod_top'] = test['production_revs'].map(lambda x: np.array(x).max() if len(x)>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value - I filled with wikipedia info\n",
    "test.loc[828,'release_date'] = '05/01/00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['year'] = test['release_date'].map(lambda x: (x.split('/'))[2])\n",
    "test['year'] = test['year'].astype(int)\n",
    "test['year'] = test['year'].map(lambda x: x+1900 if x>17 else x+2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['runtime'] = test['runtime'].fillna(107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['spoken'] = test['spoken_languages'].fillna('[{\"iso_639_1\":\"nan\"}]').map(lambda x: [a['iso_639_1'] for a in ast.literal_eval(x)])\n",
    "for u in counts:\n",
    "    if (counts[u]> limit):\n",
    "        name = f'spoken_{u}'\n",
    "        spoken_names.append(name)\n",
    "        test[name] = test['spoken'].map(lambda x: u in x).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      revenue\n",
       "id           \n",
       "3001  1000000\n",
       "3002  1000000\n",
       "3003  1000000\n",
       "3004  1000000\n",
       "3005  1000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('sample_submission.csv',index_col='id')\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['popularity','budget',\n",
    "           'l_rev',\n",
    "           'coll_rev_logav',\n",
    "           'genre_ave',\n",
    "          'prod_top','prod_ave',\n",
    "           'year', 'runtime',\n",
    "          *spoken_names]\n",
    "\n",
    "X = train[columns]\n",
    "\n",
    "X_test = test[columns]\n",
    "\n",
    "boost.fit(X,y)\n",
    "pred = boost.predict(X_test)\n",
    "pred = np.exp(pred)\n",
    "submit['revenue'] = pred\n",
    "submit.to_csv('0803-5_spok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
